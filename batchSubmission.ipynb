{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting Data to OpenAI via Batch\n",
    "\n",
    "Once the data has been prepared and formmated, it is time to submit to OpenAI. There are several steps to consider in order to complete this process successfully.\n",
    "\n",
    "- Uploading files\n",
    "- Submitting files as batch submissions\n",
    "- Checking batch status\n",
    "- Collecting batch results\n",
    "\n",
    "In order to get the ball rolling and give OpenAI access to our data, we upload our files to their API. With each upload, the API responds with some data about our upload, but most importantly it gives us a **File ID**. We need this data in order to ask OpenAI to submit our file as a batch request. Once we do though, OpenAI will give us a similar response, but now with a **Batch ID**. It is *extremely* cruicial that we keep these file and batch IDS accessible. This is because OpenAI's API functions as a sort of black box in the sense that once a submission has been made, there is no way to access it again unless you hang on to the API response that they provide when you make the submission. To address this concern, we save all of our File IDs and Batch IDs to a jsonl file which we can refer to later. It is very important that you have access to this file, as it is needed to collect the data after is has finished processing.\n",
    "\n",
    "Because batch submissions are *asynchronous* the response needs to be collected separetly from the original batch submission. OpenAI states that it will try its best to complete a submission within 24 hours, so it should take at most a day to collect the results. We handle the upload file and submit batch step in one block of code, and the collection in a separate block.\n",
    "\n",
    "The submission code below will take every batch submission file and upload it and then submit it as a batch request, and write the upload and batch submission responses to separate jsonl output files.\n",
    "\n",
    "### Input for Upload & Batch Submission\n",
    "\n",
    "- A directory containing prepared batch submission jsonl files\n",
    "- A path & name to where you want to write the .jsonl output files to (shouldn't have output files currently in it)\n",
    "- An API key from OpenAI (keep this a secret)\n",
    "- Optionally, a metadata description for the batch submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key='Your OpenAI API Key Here')\n",
    "\n",
    "# Directory containing the .jsonl files you want to upload.\n",
    "INPUT_DIRECTORY = \"your/input/directory/here\"\n",
    "\n",
    "# Output file for storing upload responses (one JSON per line).\n",
    "UPLOAD_RESPONSES_FILE = \"your/.jsonl/upload/file/path/here\"\n",
    "\n",
    "# Output file for storing batch submission responses (one JSON per line).\n",
    "BATCH_RESPONSES_FILE = \"your/.jsonl/batch/file/path/here\"\n",
    "\n",
    "def uploadInputFiles():\n",
    "    # Use glob to find all .jsonl files in the directory\n",
    "    jsonl_files = glob.glob(os.path.join(INPUT_DIRECTORY, \"*.jsonl\"))\n",
    "\n",
    "    for file_path in jsonl_files:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            # Create (upload) the file, returns a FileObject (not JSON serializable)\n",
    "            upload_response = client.files.create(\n",
    "                file=f,\n",
    "                purpose=\"batch\"\n",
    "            )\n",
    "\n",
    "            # Convert the FileObject to a JSON-serializable dict\n",
    "            serializable_response = {\n",
    "                \"id\": upload_response.id,\n",
    "                \"bytes\": upload_response.bytes,\n",
    "                \"created_at\": upload_response.created_at,\n",
    "                \"filename\": upload_response.filename,\n",
    "                \"object\": upload_response.object,\n",
    "                \"purpose\": upload_response.purpose,\n",
    "                \"status\": upload_response.status,\n",
    "                \"status_details\": upload_response.status_details,\n",
    "            }\n",
    "\n",
    "        # Append the response (as JSON) on a new line in UPLOAD_RESPONSES_FILE\n",
    "        with open(UPLOAD_RESPONSES_FILE, \"a\") as upload_out:\n",
    "            upload_out.write(json.dumps(serializable_response) + \"\\n\")\n",
    "\n",
    "    print(f\"Upload complete. Responses written to {UPLOAD_RESPONSES_FILE}\")\n",
    "\n",
    "def submitBatch():\n",
    "    # Make sure the file exists and has content\n",
    "    if not os.path.exists(UPLOAD_RESPONSES_FILE):\n",
    "        print(f\"No upload responses file found: {UPLOAD_RESPONSES_FILE}\")\n",
    "        return\n",
    "\n",
    "    with open(UPLOAD_RESPONSES_FILE, \"r\") as upload_in:\n",
    "        for line in upload_in:\n",
    "            # Safely parse JSON; skip if empty\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                upload_response = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "            # Extract the file ID from the upload response\n",
    "            file_id = upload_response.get(\"id\")\n",
    "            if not file_id:\n",
    "                # If there's no 'id' field, skip\n",
    "                continue\n",
    "\n",
    "            # Submit a batch using that file_id, returns a Batch object\n",
    "            batch_response = client.batches.create(\n",
    "                input_file_id=file_id,\n",
    "                endpoint=\"/v1/chat/completions\",\n",
    "                completion_window=\"24h\",\n",
    "                metadata={\n",
    "                    \"description\": \"Optionally, add a description\"\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Convert the Batch object to a JSON-serializable dict\n",
    "            # Note that 'request_counts' is another custom object we break into a dict.\n",
    "            batch_serializable = {\n",
    "                \"id\": batch_response.id,\n",
    "                \"completion_window\": batch_response.completion_window,\n",
    "                \"created_at\": batch_response.created_at,\n",
    "                \"endpoint\": batch_response.endpoint,\n",
    "                \"input_file_id\": batch_response.input_file_id,\n",
    "                \"object\": batch_response.object,\n",
    "                \"status\": batch_response.status,\n",
    "                \"cancelled_at\": batch_response.cancelled_at,\n",
    "                \"cancelling_at\": batch_response.cancelling_at,\n",
    "                \"completed_at\": batch_response.completed_at,\n",
    "                \"error_file_id\": batch_response.error_file_id,\n",
    "                \"errors\": batch_response.errors,\n",
    "                \"expired_at\": batch_response.expired_at,\n",
    "                \"expires_at\": batch_response.expires_at,\n",
    "                \"failed_at\": batch_response.failed_at,\n",
    "                \"finalizing_at\": batch_response.finalizing_at,\n",
    "                \"in_progress_at\": batch_response.in_progress_at,\n",
    "                \"metadata\": batch_response.metadata,\n",
    "                \"output_file_id\": batch_response.output_file_id,\n",
    "            }\n",
    "\n",
    "            # If batch_response.request_counts is another object, break it down:\n",
    "            if batch_response.request_counts:\n",
    "                batch_serializable[\"request_counts\"] = {\n",
    "                    \"completed\": batch_response.request_counts.completed,\n",
    "                    \"failed\": batch_response.request_counts.failed,\n",
    "                    \"total\": batch_response.request_counts.total,\n",
    "                }\n",
    "            else:\n",
    "                batch_serializable[\"request_counts\"] = None\n",
    "\n",
    "            # Write the batch response (as JSON) on a new line\n",
    "            with open(BATCH_RESPONSES_FILE, \"a\") as batch_out:\n",
    "                batch_out.write(json.dumps(batch_serializable) + \"\\n\")\n",
    "\n",
    "    print(f\"Batch submission complete. Responses written to {BATCH_RESPONSES_FILE}\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # SAFETY CHECKS: If the output files already exist, abort.\n",
    "    # This prevents overwriting and prevents ANY API calls.\n",
    "    if os.path.exists(UPLOAD_RESPONSES_FILE):\n",
    "        err_msg = (\n",
    "            f\"Error: The file '{UPLOAD_RESPONSES_FILE}' already exists. \"\n",
    "            \"Refusing to overwrite. Aborting operation.\"\n",
    "        )\n",
    "        print(err_msg)\n",
    "        raise FileExistsError(err_msg)\n",
    "\n",
    "    if os.path.exists(BATCH_RESPONSES_FILE):\n",
    "        err_msg = (\n",
    "            f\"Error: The file '{BATCH_RESPONSES_FILE}' already exists. \"\n",
    "            \"Refusing to overwrite. Aborting operation.\"\n",
    "        )\n",
    "        print(err_msg)\n",
    "        raise FileExistsError(err_msg)\n",
    "\n",
    "    # If we get here, both files do NOT exist, so it's safe to proceed.\n",
    "    uploadInputFiles()\n",
    "    submitBatch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting the Batch\n",
    "\n",
    "Once the 24 hour window has passed, as long as there have been no errors, the submission is likely complete. So, we can use the files generated from the batch submission to collect our data from the AI model, and write it to a jsonl file. We will have as many output files as we did input, and will write these to a specified directory. Note that without the batch id files it is impossible to retreive the data!\n",
    "\n",
    "### Necessary Elements\n",
    "\n",
    "- OpenAI API key\n",
    "- Path to batch id file\n",
    "- Path to output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key='Your API Key Here')\n",
    "\n",
    "def collect_results_from_file():\n",
    "\n",
    "    input_file_path = \"path/to/your/batch/id/file\"\n",
    "\n",
    "    output_directory = \"path/to/your/output/directory\"\n",
    "\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "        for line_number, line in enumerate(f, start=1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue  # Skip empty lines\n",
    "\n",
    "            try:\n",
    "                batch_info = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Line {line_number} is not valid JSON. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Extract the batch ID\n",
    "            batch_id = batch_info.get(\"id\")\n",
    "            if not batch_id:\n",
    "                print(f\"Line {line_number} has no 'id' field. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Retrieve the batch\n",
    "            try:\n",
    "                batch_response = client.batches.retrieve(batch_id)\n",
    "            except Exception as e:\n",
    "                print(f\"Error retrieving batch {batch_id}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Check if there's an output_file_id\n",
    "            output_file_id = batch_response.output_file_id\n",
    "            if not output_file_id:\n",
    "                print(f\"No output file for batch {batch_id}, possibly still in progress.\")\n",
    "                continue\n",
    "\n",
    "            # Retrieve the content of the output file\n",
    "            try:\n",
    "                file_response = client.files.content(output_file_id)\n",
    "            except Exception as e:\n",
    "                print(f\"Error retrieving content for output_file_id {output_file_id}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Create a unique output file name using the batch_id\n",
    "            output_file_name = f\"batch_{batch_id}.jsonl\"\n",
    "            output_file_path = os.path.join(output_directory, output_file_name)\n",
    "\n",
    "            # Write the file content to disk\n",
    "            try:\n",
    "                with open(output_file_path, \"w\", encoding='utf-8') as output_file:\n",
    "                    output_file.write(file_response.text)\n",
    "                print(f\"Saved output for batch {batch_id} to {output_file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error writing to file {output_file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "collect_results_from_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Batch Status\n",
    "\n",
    "After making the batch submission, you may want to check the status of a batch submission. In order to do this, you will need a batch id to make the API call. After it has been made, you will get a response similar to when the batch submission was executed. The most important part of this response will be the status field. There are several possibilities for what this could be, but there are a few typical ones. \"Validating\" is the status provided when the initial batch submission is made. \"in_progress\" means that the submission is currently in the queue. \"completed\" means that the submission is done and ready for collection. \"failed\" means that something went wrong with the submission. Usually, the response will inform you of the error, but likely issues would be an invalid input format, exceeding the daily token rate limit, or exceeding 50000 lines per file or 200MB per file.\n",
    "\n",
    "### Input\n",
    "- OpenAI API key\n",
    "- A single batch ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key='Your API Key Here')\n",
    "\n",
    "retrieval = client.batches.retrieve(\"batchid_here\")\n",
    "print(retrieval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
